from skimage.segmentation import find_boundaries
from skimage.measure import regionprops
from matplotlib import pyplot as plt
import numpy as np
import linecache
import shutil
import pickle
import scipy
import nrrd
import yaml
import pdb
import os

import tensorflow as tf
import patch_utils
import PW_NNAL
import PW_NN
import PW_AL
import NN


def get_queries(expr, run, method_name):
    """Simply giving back the queries generated
    in different queries separately
    """
    
    Qs = []

    Q_dir = os.path.join(
        expr.root_dir,str(run),
        method_name, 'queries')
    Q_files = os.listdir(Q_dir)
    for f in Q_files:
        fullpath = os.path.join(
            Q_dir, f)
        Qs += [np.int32(np.loadtxt(
            fullpath))]
        
    return Qs

def get_queries_type(expr,run,method_name):
    """Getting type of queries generated by
    a specific method of a run of AL experiment
    """
    
    stypes = []
    Qs = get_queries(expr, run, method_name)
    
    Q_types = []
    for Q in Qs:
        t = get_sample_type(
            expr, run, Q)
        Q_types += [t]
        
    return Q_types


def get_sample_type(expr, run, inds):
    """Getting type of a given set of
    indexed samples in a run of an
    experiment
    """

    stypes = []
    for ind in inds:
        line = linecache.getline(
            os.path.join(
                expr.root_dir,
                str(run),
                'inds.txt'), ind)
        stypes += [int(line.splitlines(
        )[0].split(',')[-1])]

    return stypes

def get_slice_preds(expr,
                    run,
                    model,
                    inds,
                    slice_,
                    sess):
    """Getting the results of 
    class prediction of a set of indexed
    voxels in a given slices of the 
    image
    """
    
    # take only indices of the 
    # given slice
    if expr.pars['data']=='adults':
        img_addrs, mask_addrs = patch_utils.extract_Hakims_data_path()
    elif expr.pars['data']=='newborn':
        img_addrs, mask_addrs = patch_utils.extract_newborn_data_path()

    img_addr = img_addrs[expr.pars[
        'indiv_img_ind']]
    img,_ = nrrd.read(img_addr)

    inds_path = os.path.join(expr.root_dir,
                             str(run),
                             'inds.txt')
    samples_dict,_ = PW_AL.create_dict(
        inds_path, inds)
    multinds = np.unravel_index(
        samples_dict[img_addr], 
        img.shape)
    slice_indics = multinds[2]==slice_
    slice_multinds = (
        multinds[0][slice_indics],
        multinds[1][slice_indics])
    slice_inds = inds[slice_indics]
    
    # prediction
    preds = PW_AL.batch_eval_winds(
        expr,
        run,
        model,
        slice_inds,
        'prediction',
        sess)
    
    return preds, slice_multinds


def visualize_eval_metrics(expr,
                           run,
                           metric,
                           methods=[],
                           colors=[]):
    """Visualize performance evaluations
    of a set of methods in an experiment's
    run

    Size of the color vector `colors` should
    be the number of included path plus
    one (if there also exists the performance
    metric value for the full pool data set)
    """

    run_path = os.path.join(expr.root_dir,
                            str(run))
    if len(methods)==0:
        methods = [f for f in os.listdir(run_path) 
                   if os.path.isdir(os.path.join(
                           run_path, f))]

    # maximum number of queries among methods
    M = 0
    for i, method_name in enumerate(methods):
        if metric=='F1':
            # vector of evaluation metrics
            F = np.loadtxt(os.path.join(
                run_path, 
                method_name,
                'perf_evals.txt'))
        elif metric=='Precision':
            F = get_eval_metrics(
                expr, run, method_name)[0,:]
        elif metric=='Recall':
            F = get_eval_metrics(
                expr, run, method_name)[1,:]


        # vector of numbre of observed
        # labels at each query iterations
        Qset = get_queries(expr, run, 
                           method_name)
        Qsizes = [0] + [len(Q) for Q in Qset]
        Qsizes = np.cumsum(Qsizes)

        # if the last iteration is still not
        # evaluated, ignore the queries
        if len(Qsizes)==len(F)+1:
            Qsizes = Qsizes[:-1]

        M = max(M, Qsizes[-1])
        # plotting this curve
        if len(colors)>0:
            plt.plot(Qsizes, F, 
                     linewidth=2,
                     color=colors[i],
                     marker = '*',
                     label=method_name)
        else:
            plt.plot(Qsizes, F, 
                     linewidth=2,
                     marker='*',
                     label=method_name)

    # get the full performance 
    if os.path.exists(os.path.join(
            run_path, 
            'pooltrain_eval.txt')):
        full_F = np.loadtxt(os.path.join(
            run_path, 
            'pooltrain_eval.txt'))

        if len(colors)>0:
            plt.plot([0,M], 
                     [full_F, full_F],
                     linewidth=2,
                     color=colors[-1],
                     label='Pool-training')
        else:
            plt.plot([0,M], 
                     [full_F, full_F], 
                     linewidth=2,
                     label='Pool-training')

    plt.legend(fontsize=15)
    plt.xlabel('# Queries', fontsize=15)
    plt.ylabel(metric, fontsize=15)
    plt.grid()

def get_preds_stats(preds, mask):
    """Computing different statistics of
    a set of prediction in comparison with
    the ground truth labels, such as P, N, 
    TP, TN, FP, FN
    
    At this time, this function deals only
    with single images (and not a dictionary
    of multiple images). That is to say, the
    inputs are two arrays of the same size, 
    and with binary values (0 or 1)
    """

    P = float(np.sum(mask>0))
    N = float(np.sum(mask==0))
    TP = float(np.sum(np.logical_and(
        preds>0, mask>0)))
    FP = float(np.sum(np.logical_and(
        preds>0, mask==0)))
    TN = float(np.sum(np.logical_and(
        preds==0, mask==0)))
    FN = float(np.sum(np.logical_and(
        preds==0, mask>0)))

    return P, N, TP, FP, TN, FN
    

def get_Fmeasure(preds, mask):
    
    # computing total TPs, Ps, and
    # TPFPs (all positives)
    P  = 0
    TP = 0
    TPFP = 0
    if isinstance(preds, dict):
        for img_path in list(preds.keys()):
            ipreds = preds[img_path]
            imask = np.array(mask[img_path])
            
            P  += np.sum(imask>0)
            TP += np.sum(np.logical_and(
                ipreds>0, imask>0))
            TPFP += np.sum(ipreds>0)
    else:
        
        P  += np.sum(mask>0)
        TP += np.sum(np.logical_and(
            preds>0, mask>0))
        TPFP += np.sum(preds>0)

    # precision and recall
    Pr = TP / TPFP
    Rc = TP / P
    
    # F measure
    return 2/(1/Pr + 1/Rc)

def get_eval_metrics(expr,
                     run,
                     method_name):
    """Computing different evaluation
    metrics of the predictions in results
    of running a specific querying
    method in an experiment's run
    """

    run_path = os.path.join(
        expr.root_dir, str(run))

    # load ground truth labels
    labels_path = os.path.join(
        run_path, 'labels.txt')
    test_lines = np.int64(np.loadtxt(
        os.path.join(run_path, 
                     'test_lines.txt')))
    test_labels = PW_AL.read_label_lines(
        labels_path, test_lines)

    # load predictions
    preds_path = os.path.join(
        run_path, 
        method_name, 
        'predicts.txt')
    preds = np.loadtxt(preds_path)
    
    iter_cnt = preds.shape[0]
    Metrs = np.zeros((2, iter_cnt))
    for i in range(iter_cnt):
        (P, N, TP, 
         FP, TN, FN) = get_preds_stats(
             preds[i,:], test_labels)
        
        # Precision
        Metrs[0,i] = TP / (TP+FP)
        # Recall
        Metrs[1,i] = TP / P

    return Metrs
    
def mask_SuPix(overseg_img,
               SuPix_codes,
               show_bound=True):
    """Visualizing some super-pixels in
    the over-segmentation image where the 
    boundaries of all the super-pixels
    are shown, and the selected ones
    are high-lighted
    """

    s = overseg_img.shape

    masked_SuPix = np.zeros(
        s, dtype=bool)

    # get the boundaries if necessary
    if show_bound:
        for i in range(s[2]):
            masked_SuPix[:,:,i
            ] = find_boundaries(
                overseg_img[:,:,i])

    # selected superpixels slices
    slices = np.unique(SuPix_codes[0,:])
    for j in slices:
        props = regionprops(
            overseg_img[:,:,j])
        SuPix_labels = SuPix_codes[
            1, SuPix_codes[0,:]==j]
        n_overseg = len(props)
        prop_labels = [props[i]['label']
                      for i in 
                      range(n_overseg)]
        # mask the super-pixels
        for label in SuPix_labels:
            label_loc = np.where(
                prop_labels==label)[0][0]
            # indices of the pixels in 
            # this super-pixel
            multinds_2D = props[
                label_loc]['coords']
            vol = len(multinds_2D[:,0])
            multinds_3D = (
                multinds_2D[:,0],
                multinds_2D[:,1],
                np.ones(vol,dtype=int)*j)

            masked_SuPix[multinds_3D] = True

    return masked_SuPix
            

def full_model_eval(expr,
                    run,
                    method_name,
                    img_path,
                    mask_path,
                    slice_inds,
                    save_dir=None):
    """Evaluating the last model of a querying
    method in an experiment's run
    """

    if len(method_name)>0:
        method_path = os.path.join(
            expr.root_dir, str(run),
            method_name)
        weights_path = os.path.join(
            method_path, 'curr_weights.h5')
    else:
        weights_path = expr.pars[
            'init_weights_path']

    mask,_ = nrrd.read(mask_path)

    # make the model ready
    model = NN.create_model(
        expr.pars['model_name'],
        expr.pars['dropout_rate'],
        expr.nclass,
        expr.pars['learning_rate'],
        expr.pars['grad_layers'],
        expr.pars['train_layers'],
        expr.pars['optimizer_name'],
        expr.pars['patch_shape'])

    # start TF session to do the prediction
    with tf.Session() as sess:
        print("Loading model with weights %s"% 
              weights_path)
        # loading the weights into the model
        model.initialize_graph(sess)
        model.load_weights(
            weights_path, sess)

        # get the predictins
        slice_evals = full_slice_eval(
            model,
            img_path,
            slice_inds,
            'axial',
            expr.pars['patch_shape'],
            expr.pars['ntb'],
            expr.pars['stats'],
            sess)
        
    # creating an array with the same
    # shape as the mask
    test_mask = mask[:,:,slice_inds]
    test_evals = np.zeros(test_mask.shape)
    for i in range(len(slice_inds)):
        test_evals[:,:,i] = slice_evals[i]

    # computing F-measure
    P,N,TP,FP,TN,FN = get_preds_stats(
        test_evals,test_mask)
    Pr = TP/(TP+FP)
    Rc = TP/P
    F1 = 2./(1/Pr+1/Rc)

    # save the results if necessary
    # this save_path will be created inside the
    # method's directory
    if save_dir:
        if not(os.path.exists(save_dir)):
            os.mkdir(save_dir)

        # save the results itself
        np.save(os.path.join(save_dir, 'segs.npy'),
                test_evals)
        np.savetxt(os.path.join(save_dir,
                                'test_slice_inds.txt'),
                   slice_inds)
            
        # save the results, with showing both
        # model evaluations and mask boundaries
        img,_ = nrrd.read(img_path)
        for i in range(len(slice_inds)):
            slice_ = img[:,:,slice_inds[i]]
            mask_bound = find_boundaries(
                mask[:,:,slice_inds[i]])
            rgb_result = patch_utils.generate_rgb_mask(
                slice_, test_evals[:,:,i], mask_bound)
            
            fig = plt.figure(figsize=(7,7))
            plt.imshow(rgb_result, cmap='gray')
            plt.axis('off')
            plt.savefig(os.path.join(
                save_dir,'%d.png'% (slice_inds[i])), 
                        bbox_inches='tight')
            plt.close(fig)

    return test_evals, F1


def full_slice_eval(model,
                    img_path,
                    slice_inds,
                    slice_view,
                    patch_shape,
                    batch_size,
                    stats,
                    sess,
                    varname='prediction'):
    """Generating prediction of all voxels
    in a few slices of a given image
    """
    
    img,_ = nrrd.read(img_path)
    img_shape = img.shape
    
    # preparing 3D indices of the slices
    # ---------------------------------
    # first preparing 2D single indices
    if slice_view=='sagittal':
        nvox_slice=img_shape[1]*img_shape[2]
        slice_shape = img[0,:,:].shape
    elif slice_view=='coronal':
        nvox_slice=img_shape[0]*img_shape[2]
        slice_shape = img[:,0,:].shape
    elif slice_view=='axial':
        nvox_slice=img_shape[0]*img_shape[1]
        slice_shape = img[:,:,0].shape        
        
    inds_2D = np.arange(0, nvox_slice)
    
    # single to multiple 2D indices
    # (common for all slices)
    multiinds_2D = np.unravel_index(
        inds_2D, slice_shape)
    
    slice_evals = []
    for i in range(len(slice_inds)):
        extra_inds = np.ones(
            len(inds_2D),
            dtype=int)*slice_inds[i]

        # multi 2D to multi 3D indices
        if slice_view=='sagittal':
            multiinds_3D = (extra_inds,) + \
                              multiinds_2D
        elif slice_view=='coronal':
            multiinds_3D = multiinds_2D[:1] +\
                              (extra_inds,) +\
                              multiinds_2D[1:]
        elif slice_view=='axial':
            multiinds_3D = multiinds_2D +\
                           (extra_inds,)
        
        # multi 3D to single 3D indices
        inds_3D = np.ravel_multi_index(
            multiinds_3D, img_shape)
        # get the prediction for this slice
        inds_dict = {img_path: inds_3D}

        evals = PW_NN.batch_eval(model,
                                 inds_dict,
                                 patch_shape,
                                 batch_size,
                                 stats,
                                 sess,
                                 varname)
        # prediction map
        eval_map = np.zeros(slice_shape)
        eval_map[multiinds_2D] = evals[0][img_path]
        slice_evals += [eval_map]

        print('%d / %d'% 
              (i,len(slice_inds)))

    return slice_evals
